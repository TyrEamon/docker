package crawler

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"strings"
	"time"

	"my-bot-go/internal/config"
	"my-bot-go/internal/database"
	"my-bot-go/internal/telegram"

	"github.com/go-resty/resty/v2"
)

type CosineImage struct {
	ID        int      `json:"id"`
	PID       string   `json:"pid"`
	Title     string   `json:"title"`
	Author    string   `json:"author"`
	RawURL    string   `json:"rawurl"`
	ThumbURL  string   `json:"thumburl"`
	Extension string   `json:"extension"`
	Filename  string   `json:"filename"`
	Tags      []string `json:"tags"`
	Width     int      `json:"width"`
	Height    int      `json:"height"`
	Platform  string   `json:"platform"`
}

func StartCosineTag(ctx context.Context, cfg *config.Config, db *database.D1Client, botHandler *telegram.BotHandler) {
	if len(cfg.CosineTags) == 0 {
		log.Printf("âš ï¸ No CosineTags configured. Skipping Cosine Crawler.")
		return
	}

	client := resty.New()
	client.SetTimeout(30 * time.Second)

	indexHeaders := map[string]string{
		"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
		"Referer":    "https://pic.cosine.ren/",
	}

	pixivHeaders := map[string]string{
		"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
		"Referer":    "https://www.pixiv.net/",
	}

	log.Println("ğŸš€ Starting Cosine Tag Crawler...")
	log.Printf("ğŸ¯ Target Tags: %v", cfg.CosineTags)
	log.Printf("ğŸ“Š Limit Per Tag: %d", cfg.CosineLimitPerTag)

	for {
		select {
		case <-ctx.Done():
			return
		default:
			for _, tag := range cfg.CosineTags {
				log.Printf("ğŸ·ï¸  Scanning Tag: %s", tag)
				
				processedCount := 0
				start := 0
				limit := 32

				for processedCount < cfg.CosineLimitPerTag {
					apiURL := "https://pic.cosine.ren/api/tag"
					resp, err := client.R().
						SetHeaders(indexHeaders).
						SetQueryParams(map[string]string{
							"tag":   tag,
							"start": fmt.Sprintf("%d", start),
							"limit": fmt.Sprintf("%d", limit),
						}).Get(apiURL)

					if err != nil || resp.StatusCode() != 200 {
						log.Printf("âŒ API Request Failed for tag %s: %v", tag, err)
						break
					}

					var images []CosineImage
					if err := json.Unmarshal(resp.Body(), &images); err != nil {
						log.Printf("âŒ JSON Unmarshal Failed: %v", err)
						break
					}

					if len(images) == 0 {
						log.Println("ğŸ No more images for this tag.")
						break
					}

					log.Printf("ğŸ“„ Fetched %d images (start=%d)", len(images), start)

					for _, img := range images {
						if processedCount >= cfg.CosineLimitPerTag {
							break
						}

						// ================= ID ç”Ÿæˆä¿®æ­£é€»è¾‘ =================
						// å¼ºåˆ¶ä½¿ç”¨æ ‡å‡†æ ¼å¼ï¼špixiv_{PID}_p{Page}
						pidStr := img.PID
						pagePart := "_p0" // é»˜è®¤ä¸º p0
						
						// å°è¯•ä»æ–‡ä»¶åè§£æ _p1, _p2 ç­‰
						if strings.Contains(img.Filename, "_p") {
							start := strings.LastIndex(img.Filename, "_p")
							if start != -1 {
								rest := img.Filename[start:]
								if dot := strings.Index(rest, "."); dot != -1 {
									pagePart = rest[:dot]
								} else {
									pagePart = rest
								}
							}
						}

						// æ„é€ æ ‡å‡† DB Key (æ— åç¼€)
						dbKey := fmt.Sprintf("pixiv_%s%s", pidStr, pagePart)

						// ğŸ›¡ï¸ è¶…çº§å»é‡é˜²å¾¡ (åŒæ—¶æŸ¥å¸¦åç¼€å’Œä¸å¸¦åç¼€çš„)
						if db.History[dbKey] || 
						   db.History[dbKey+".jpg"] || 
						   db.History[dbKey+".png"] || 
						   db.History[dbKey+".webp"] {
							// log.Printf("â™»ï¸ Skip %s (Already in DB)", dbKey)
							continue
						}

						// ================= ä¸‹è½½é€»è¾‘ =================
						
						var imgData []byte
						var finalExt string = ".jpg"

						// 1. ä¼˜å…ˆå°è¯• Pixiv åŸé“¾
						downloadURL := img.RawURL
						if downloadURL == "" {
							downloadURL = img.ThumbURL
						}

						// ä¿®æ­£ extension
						if img.Extension != "" {
							finalExt = "." + img.Extension
						}

						log.Printf("â¬‡ï¸  Downloading: %s (%s)", img.Title, dbKey)

						dlHeaders := indexHeaders
						if strings.Contains(downloadURL, "pximg.net") {
							dlHeaders = pixivHeaders
						}

						imgResp, err := client.R().SetHeaders(dlHeaders).Get(downloadURL)
						success := (err == nil && imgResp.StatusCode() == 200)

						// 2. ğŸš¨ å¤‡ç”¨æ–¹æ¡ˆ (å·å®¶æˆ˜æœ¯)
						if !success {
							log.Printf("âš ï¸ Primary Source Failed, trying Cosine Backup...")
							
							platformDir := "pixiv"
							if strings.Contains(img.RawURL, "twimg.com") || img.Platform == "twitter" {
								platformDir = "twitter"
							}

							backupBase := fmt.Sprintf("https://backblaze.cosine.ren/pic/origin/%s/", platformDir)
							
							// ç­–ç•¥ A: åŸå§‹æ–‡ä»¶å
							backupURL := backupBase + img.Filename
							log.Printf("ğŸ”„ Trying Backup A: %s", backupURL)
							imgResp, err = client.R().SetHeaders(indexHeaders).Get(backupURL)

							if err == nil && imgResp.StatusCode() == 200 {
								success = true
							} else {
								// ç­–ç•¥ B: å¼ºåˆ¶ .webp
								nameNoExt := img.Filename
								if idx := strings.LastIndex(img.Filename, "."); idx != -1 {
									nameNoExt = img.Filename[:idx]
								}
								backupURL = backupBase + nameNoExt + ".webp"
								log.Printf("ğŸ”„ Trying Backup B: %s", backupURL)
								imgResp, err = client.R().SetHeaders(indexHeaders).Get(backupURL)
								
								if err == nil && imgResp.StatusCode() == 200 {
									success = true
									finalExt = ".webp"
								}
							}
						}

						if !success {
							log.Printf("âŒ All sources failed for: %s, Skipping.", dbKey)
							continue
						}
						
						imgData = imgResp.Body()

						// ================= å‘é€ä¸å­˜å‚¨ =================

						cleanTitle := strings.TrimSpace(img.Title)
						tagsStr := strings.Join(img.Tags, " #")
						caption := fmt.Sprintf("Title: %s\nArtist: %s\nTags: #%s\nSource: %s",
							cleanTitle, img.Author, tagsStr, "pic.cosine.ren")
						
						// æ„é€ å‘ç»™ TG çš„æ–‡ä»¶å (å¿…é¡»å¸¦åç¼€ï¼Œéª—è¿‡ TG)
						sendID := dbKey + finalExt

						// å‘é€
						botHandler.ProcessAndSend(ctx, imgData, sendID, strings.Join(img.Tags, " "), caption, "pixiv", img.Width, img.Height)
                        
                        // å­˜åº“ (å­˜æ ‡å‡† Keyï¼Œæ— åç¼€)
                        // æ³¨æ„ï¼šè¿™é‡Œæ˜¾å¼è°ƒç”¨ PushHistoryï¼Œé˜²æ­¢ ProcessAndSend æ²¡å­˜å¯¹
                        db.History[dbKey] = true
                        db.PushHistory()
                        
                        processedCount++
                        time.Sleep(4 * time.Second)
					}
					
					start += limit
					time.Sleep(2 * time.Second)
				}
			}

			log.Println("ğŸ˜´ Cosine Crawler Cycle Done. Sleeping 2 hours...")
			time.Sleep(2 * time.Hour)
		}
	}
}
